{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNA to RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna=\"\"\"TGGCTTATTCACTAAGGATTCTTAAGGTTTTCTTAATAGTTTTCTACGTCGGCATGCGATTGTTTGGTTTAGAAGACTGCTTTCTAAATATGGTTGGGTGTATTTAAGCTAGACCCATACACCCGCTCTATGGGATTATTTACTTGTTTGAATTTTAAGATTTGTGATAATGGAACTGGACGCAAACATTTGATGGAAAACGCATGTCATCATTAACGAGGTAACGTAGGTATCTGTCCTGCCTTAGTATTGCACGCAGCTTCCCAGGACGCCTAGCTATTTTTTCATCTATTCCCCTCTGTAGTAACGTAAGAGTTTTCAAGTTTTTAATTCAGACTTTCTCTTCCTTTGTTTCCAATTTCCTTCCTTACTGCTTGATACCTTTTCAATCCCAAAGAAACCGTGTTCTTTATATATTGTCGATTGAAAGTTACCTACATCAACTTTCCGTGTTCCATTCCGACTATAACAAACAACCAATAAGCTCAACTAATTAAGTA\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPS2 Promoter medium blue mutation in yeast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna= dna.replace(\"T\", \"U\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UGGCUUAUUCACUAAGGAUUCUUAAGGUUUUCUUAAUAGUUUUCUACGUCGGCAUGCGAUUGUUUGGUUUAGAAGACUGCUUUCUAAAUAUGGUUGGGUGUAUUUAAGCUAGACCCAUACACCCGCUCUAUGGGAUUAUUUACUUGUUUGAAUUUUAAGAUUUGUGAUAAUGGAACUGGACGCAAACAUUUGAUGGAAAACGCAUGUCAUCAUUAACGAGGUAACGUAGGUAUCUGUCCUGCCUUAGUAUUGCACGCAGCUUCCCAGGACGCCUAGCUAUUUUUUCAUCUAUUCCCCUCUGUAGUAACGUAAGAGUUUUCAAGUUUUUAAUUCAGACUUUCUCUUCCUUUGUUUCCAAUUUCCUUCCUUACUGCUUGAUACCUUUUCAAUCCCAAAGAAACCGUGUUCUUUAUAUAUUGUCGAUUGAAAGUUACCUACAUCAACUUUCCGUGUUCCAUUCCGACUAUAACAAACAACCAAUAAGCUCAACUAAUUAAGUA'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = [rna[i:i+3] for i in range(0, len(rna), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UGG',\n",
       " 'CUU',\n",
       " 'AUU',\n",
       " 'CAC',\n",
       " 'UAA',\n",
       " 'GGA',\n",
       " 'UUC',\n",
       " 'UUA',\n",
       " 'AGG',\n",
       " 'UUU',\n",
       " 'UCU',\n",
       " 'UAA',\n",
       " 'UAG',\n",
       " 'UUU',\n",
       " 'UCU',\n",
       " 'ACG',\n",
       " 'UCG',\n",
       " 'GCA',\n",
       " 'UGC',\n",
       " 'GAU',\n",
       " 'UGU',\n",
       " 'UUG',\n",
       " 'GUU',\n",
       " 'UAG',\n",
       " 'AAG',\n",
       " 'ACU',\n",
       " 'GCU',\n",
       " 'UUC',\n",
       " 'UAA',\n",
       " 'AUA',\n",
       " 'UGG',\n",
       " 'UUG',\n",
       " 'GGU',\n",
       " 'GUA',\n",
       " 'UUU',\n",
       " 'AAG',\n",
       " 'CUA',\n",
       " 'GAC',\n",
       " 'CCA',\n",
       " 'UAC',\n",
       " 'ACC',\n",
       " 'CGC',\n",
       " 'UCU',\n",
       " 'AUG',\n",
       " 'GGA',\n",
       " 'UUA',\n",
       " 'UUU',\n",
       " 'ACU',\n",
       " 'UGU',\n",
       " 'UUG',\n",
       " 'AAU',\n",
       " 'UUU',\n",
       " 'AAG',\n",
       " 'AUU',\n",
       " 'UGU',\n",
       " 'GAU',\n",
       " 'AAU',\n",
       " 'GGA',\n",
       " 'ACU',\n",
       " 'GGA',\n",
       " 'CGC',\n",
       " 'AAA',\n",
       " 'CAU',\n",
       " 'UUG',\n",
       " 'AUG',\n",
       " 'GAA',\n",
       " 'AAC',\n",
       " 'GCA',\n",
       " 'UGU',\n",
       " 'CAU',\n",
       " 'CAU',\n",
       " 'UAA',\n",
       " 'CGA',\n",
       " 'GGU',\n",
       " 'AAC',\n",
       " 'GUA',\n",
       " 'GGU',\n",
       " 'AUC',\n",
       " 'UGU',\n",
       " 'CCU',\n",
       " 'GCC',\n",
       " 'UUA',\n",
       " 'GUA',\n",
       " 'UUG',\n",
       " 'CAC',\n",
       " 'GCA',\n",
       " 'GCU',\n",
       " 'UCC',\n",
       " 'CAG',\n",
       " 'GAC',\n",
       " 'GCC',\n",
       " 'UAG',\n",
       " 'CUA',\n",
       " 'UUU',\n",
       " 'UUU',\n",
       " 'CAU',\n",
       " 'CUA',\n",
       " 'UUC',\n",
       " 'CCC',\n",
       " 'UCU',\n",
       " 'GUA',\n",
       " 'GUA',\n",
       " 'ACG',\n",
       " 'UAA',\n",
       " 'GAG',\n",
       " 'UUU',\n",
       " 'UCA',\n",
       " 'AGU',\n",
       " 'UUU',\n",
       " 'UAA',\n",
       " 'UUC',\n",
       " 'AGA',\n",
       " 'CUU',\n",
       " 'UCU',\n",
       " 'CUU',\n",
       " 'CCU',\n",
       " 'UUG',\n",
       " 'UUU',\n",
       " 'CCA',\n",
       " 'AUU',\n",
       " 'UCC',\n",
       " 'UUC',\n",
       " 'CUU',\n",
       " 'ACU',\n",
       " 'GCU',\n",
       " 'UGA',\n",
       " 'UAC',\n",
       " 'CUU',\n",
       " 'UUC',\n",
       " 'AAU',\n",
       " 'CCC',\n",
       " 'AAA',\n",
       " 'GAA',\n",
       " 'ACC',\n",
       " 'GUG',\n",
       " 'UUC',\n",
       " 'UUU',\n",
       " 'AUA',\n",
       " 'UAU',\n",
       " 'UGU',\n",
       " 'CGA',\n",
       " 'UUG',\n",
       " 'AAA',\n",
       " 'GUU',\n",
       " 'ACC',\n",
       " 'UAC',\n",
       " 'AUC',\n",
       " 'AAC',\n",
       " 'UUU',\n",
       " 'CCG',\n",
       " 'UGU',\n",
       " 'UCC',\n",
       " 'AUU',\n",
       " 'CCG',\n",
       " 'ACU',\n",
       " 'AUA',\n",
       " 'ACA',\n",
       " 'AAC',\n",
       " 'AAC',\n",
       " 'CAA',\n",
       " 'UAA',\n",
       " 'GCU',\n",
       " 'CAA',\n",
       " 'CUA',\n",
       " 'AUU',\n",
       " 'AAG',\n",
       " 'UA']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parts of speech ft rna codon table (proteins = POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homers epic poems iliad and odyssey. Despictions of the sea and the sky before the notion of blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open document and spacy all the text\n",
    "src_txt = open(\"goetheblue.txt\").read().lower()\n",
    "doc = nlp(src_txt)\n",
    "text = [word.text for word in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as as\n",
      "yellow yellow\n",
      "is be\n",
      "always always\n",
      "accompanied accompany\n",
      "with with\n",
      "light light\n",
      ", ,\n",
      "so so\n",
      "it -PRON-\n",
      "may may\n",
      "be be\n",
      "said say\n",
      "that that\n",
      "blue blue\n",
      "still still\n",
      "brings bring\n",
      "a a\n",
      "principle principle\n",
      "of of\n",
      "darkness darkness\n",
      "with with\n",
      "it -PRON-\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "this this\n",
      "color color\n",
      "has have\n",
      "a a\n",
      "peculiar peculiar\n",
      "and and\n",
      "almost almost\n",
      "indescribable indescribable\n",
      "effect effect\n",
      "on on\n",
      "the the\n",
      "eye eye\n",
      ". .\n",
      "as as\n",
      "a a\n",
      "hue hue\n",
      "it -PRON-\n",
      "is be\n",
      "powerful powerful\n",
      "— --\n",
      "but but\n",
      "it -PRON-\n",
      "is be\n",
      "on on\n",
      "the the\n",
      "negative negative\n",
      "side side\n",
      ", ,\n",
      "and and\n",
      "in in\n",
      "its -PRON-\n",
      "highest high\n",
      "purity purity\n",
      "is be\n",
      ", ,\n",
      "as as\n",
      "it -PRON-\n",
      "were be\n",
      ", ,\n",
      "a a\n",
      "stimulating stimulating\n",
      "negation negation\n",
      ". .\n",
      "its -PRON-\n",
      "appearance appearance\n",
      ", ,\n",
      "then then\n",
      ", ,\n",
      "is be\n",
      "a a\n",
      "kind kind\n",
      "of of\n",
      "contradiction contradiction\n",
      "between between\n",
      "excitement excitement\n",
      "and and\n",
      "repose repose\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "as as\n",
      "the the\n",
      "upper upper\n",
      "sky sky\n",
      "and and\n",
      "distant distant\n",
      "mountains mountain\n",
      "appear appear\n",
      "blue blue\n",
      ", ,\n",
      "so so\n",
      "a a\n",
      "blue blue\n",
      "surface surface\n",
      "seems seem\n",
      "to to\n",
      "retire retire\n",
      "from from\n",
      "us -PRON-\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "but but\n",
      "as as\n",
      "we -PRON-\n",
      "readily readily\n",
      "follow follow\n",
      "an an\n",
      "agreeable agreeable\n",
      "object object\n",
      "that that\n",
      "flies fly\n",
      "from from\n",
      "us -PRON-\n",
      ", ,\n",
      "so so\n",
      "we -PRON-\n",
      "love love\n",
      "to to\n",
      "contemplate contemplate\n",
      "blue blue\n",
      "— --\n",
      "not not\n",
      "because because\n",
      "it -PRON-\n",
      "advances advance\n",
      "to to\n",
      "us -PRON-\n",
      ", ,\n",
      "but but\n",
      "because because\n",
      "it -PRON-\n",
      "draws draw\n",
      "us -PRON-\n",
      "after after\n",
      "it -PRON-\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "blue blue\n",
      "gives give\n",
      "us -PRON-\n",
      "an an\n",
      "impression impression\n",
      "of of\n",
      "cold cold\n",
      ", ,\n",
      "and and\n",
      "thus thus\n",
      ", ,\n",
      "again again\n",
      ", ,\n",
      "reminds remind\n",
      "us -PRON-\n",
      "of of\n",
      "shade shade\n",
      ". .\n",
      "we -PRON-\n",
      "have have\n",
      "before before\n",
      "spoken speak\n",
      "of of\n",
      "its -PRON-\n",
      "affinity affinity\n",
      "with with\n",
      "black black\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "rooms room\n",
      "which which\n",
      "are be\n",
      "hung hang\n",
      "with with\n",
      "pure pure\n",
      "blue blue\n",
      ", ,\n",
      "appear appear\n",
      "in in\n",
      "some some\n",
      "degree degree\n",
      "larger large\n",
      ", ,\n",
      "but but\n",
      "at at\n",
      "the the\n",
      "same same\n",
      "time time\n",
      "empty empty\n",
      "and and\n",
      "cold cold\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "the the\n",
      "appearance appearance\n",
      "of of\n",
      "objects object\n",
      "seen see\n",
      "through through\n",
      "a a\n",
      "blue blue\n",
      "glass glass\n",
      "is be\n",
      "gloomy gloomy\n",
      "and and\n",
      "melancholy melancholy\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "when when\n",
      "blue blue\n",
      "partakes partake\n",
      "in in\n",
      "some some\n",
      "degree degree\n",
      "of of\n",
      "the the\n",
      "plus plus\n",
      "side side\n",
      ", ,\n",
      "the the\n",
      "effect effect\n",
      "is be\n",
      "not not\n",
      "disagreeable disagreeable\n",
      ". .\n",
      "sea sea\n",
      "- -\n",
      "green green\n",
      "is be\n",
      "rather rather\n",
      "a a\n",
      "pleasing pleasing\n",
      "color color\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "we -PRON-\n",
      "found find\n",
      "yellow yellow\n",
      "very very\n",
      "soon soon\n",
      "tending tend\n",
      "to to\n",
      "the the\n",
      "intense intense\n",
      "state state\n",
      ", ,\n",
      "and and\n",
      "we -PRON-\n",
      "observe observe\n",
      "the the\n",
      "same same\n",
      "progression progression\n",
      "in in\n",
      "blue blue\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "blue blue\n",
      "deepens deepen\n",
      "very very\n",
      "mildly mildly\n",
      "into into\n",
      "red red\n",
      ", ,\n",
      "and and\n",
      "thus thus\n",
      "acquires acquire\n",
      "a a\n",
      "somewhat somewhat\n",
      "active active\n",
      "character character\n",
      ", ,\n",
      "although although\n",
      "it -PRON-\n",
      "is be\n",
      "on on\n",
      "the the\n",
      "passive passive\n",
      "side side\n",
      ". .\n",
      "its -PRON-\n",
      "exciting exciting\n",
      "power power\n",
      "is be\n",
      ", ,\n",
      "however however\n",
      ", ,\n",
      "of of\n",
      "a a\n",
      "different different\n",
      "kind kind\n",
      "from from\n",
      "that that\n",
      "of of\n",
      "the the\n",
      "red red\n",
      "- -\n",
      "yellow yellow\n",
      ". .\n",
      "it -PRON-\n",
      "may may\n",
      "be be\n",
      "said say\n",
      "to to\n",
      "disturb disturb\n",
      ", ,\n",
      "rather rather\n",
      "than than\n",
      "enliven enliven\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "as as\n",
      "augmentation augmentation\n",
      "itself -PRON-\n",
      "is be\n",
      "not not\n",
      "to to\n",
      "be be\n",
      "arrested arrest\n",
      ", ,\n",
      "so so\n",
      "we -PRON-\n",
      "feel feel\n",
      "an an\n",
      "inclination inclination\n",
      "to to\n",
      "follow follow\n",
      "the the\n",
      "progress progress\n",
      "of of\n",
      "the the\n",
      "color color\n",
      ", ,\n",
      "not not\n",
      ", ,\n",
      "however however\n",
      ", ,\n",
      "as as\n",
      "in in\n",
      "the the\n",
      "case case\n",
      "of of\n",
      "the the\n",
      "red red\n",
      "- -\n",
      "yellow yellow\n",
      ", ,\n",
      "to to\n",
      "see see\n",
      "it -PRON-\n",
      "still still\n",
      "increase increase\n",
      "in in\n",
      "the the\n",
      "active active\n",
      "sense sense\n",
      ", ,\n",
      "but but\n",
      "to to\n",
      "find find\n",
      "a a\n",
      "point point\n",
      "to to\n",
      "rest rest\n",
      "in in\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "in in\n",
      "a a\n",
      "very very\n",
      "attenuated attenuate\n",
      "state state\n",
      ", ,\n",
      "this this\n",
      "color color\n",
      "is be\n",
      "known know\n",
      "to to\n",
      "us -PRON-\n",
      "under under\n",
      "the the\n",
      "name name\n",
      "of of\n",
      "lilac lilac\n",
      "; ;\n",
      "but but\n",
      "even even\n",
      "in in\n",
      "this this\n",
      "degree degree\n",
      "it -PRON-\n",
      "has have\n",
      "a a\n",
      "something something\n",
      "lively lively\n",
      "without without\n",
      "gladness gladness\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "this this\n",
      "unquiet unquiet\n",
      "feeling feeling\n",
      "increases increase\n",
      "as as\n",
      "the the\n",
      "hue hue\n",
      "progresses progress\n",
      ", ,\n",
      "and and\n",
      "it -PRON-\n",
      "may may\n",
      "be be\n",
      "safely safely\n",
      "assumed assume\n",
      ", ,\n",
      "that that\n",
      "a a\n",
      "carpet carpet\n",
      "of of\n",
      "a a\n",
      "perfectly perfectly\n",
      "pure pure\n",
      "deep deep\n",
      "blue blue\n",
      "- -\n",
      "red red\n",
      "would would\n",
      "be be\n",
      "intolerable intolerable\n",
      ". .\n",
      "on on\n",
      "this this\n",
      "account account\n",
      ", ,\n",
      "when when\n",
      "it -PRON-\n",
      "is be\n",
      "used use\n",
      "for for\n",
      "dress dress\n",
      ", ,\n",
      "ribbons ribbon\n",
      ", ,\n",
      "or or\n",
      "other other\n",
      "ornaments ornament\n",
      ", ,\n",
      "it -PRON-\n",
      "is be\n",
      "employed employ\n",
      "in in\n",
      "a a\n",
      "very very\n",
      "attenuated attenuated\n",
      "and and\n",
      "light light\n",
      "state state\n",
      ", ,\n",
      "and and\n",
      "thus thus\n",
      "displays display\n",
      "its -PRON-\n",
      "character character\n",
      "as as\n",
      "above above\n",
      "defined define\n",
      ", ,\n",
      "in in\n",
      "a a\n",
      "peculiarly peculiarly\n",
      "attractive attractive\n",
      "manner manner\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "as as\n",
      "the the\n",
      "higher high\n",
      "dignitaries dignitary\n",
      "of of\n",
      "the the\n",
      "church church\n",
      "have have\n",
      "appropriated appropriate\n",
      "this this\n",
      "unquiet unquiet\n",
      "color color\n",
      "to to\n",
      "themselves -PRON-\n",
      ", ,\n",
      "we -PRON-\n",
      "may may\n",
      "venture venture\n",
      "to to\n",
      "say say\n",
      "that that\n",
      "it -PRON-\n",
      "unceasingly unceasingly\n",
      "aspires aspire\n",
      "to to\n",
      "the the\n",
      "cardinal cardinal\n",
      "’s ’s\n",
      "red red\n",
      "through through\n",
      "the the\n",
      "restless restless\n",
      "degrees degree\n",
      "of of\n",
      "a a\n",
      "still still\n",
      "impatient impatient\n",
      "progression progression\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "should should\n",
      "your -PRON-\n",
      "glance glance\n",
      "on on\n",
      "mornings morning\n",
      "lovely lovely\n",
      "\n",
      " \n",
      "\n",
      "lift lift\n",
      "to to\n",
      "drink drink\n",
      "the the\n",
      "heaven heaven\n",
      "'s 's\n",
      "blue blue\n",
      "\n",
      " \n",
      "\n",
      "or or\n",
      "when when\n",
      "sun sun\n",
      ", ,\n",
      "veiled veil\n",
      "by by\n",
      "sirocco sirocco\n",
      ", ,\n",
      "\n",
      " \n",
      "\n",
      "royal royal\n",
      "red red\n",
      "sinks sink\n",
      "out out\n",
      "of of\n",
      "view view\n",
      "– –\n",
      "\n",
      " \n",
      "\n",
      "give give\n",
      "to to\n",
      "nature nature\n",
      "praise praise\n",
      "and and\n",
      "honor honor\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "blithe blithe\n",
      "of of\n",
      "heart heart\n",
      "and and\n",
      "sound sound\n",
      "of of\n",
      "eye eye\n",
      ", ,\n",
      "s s\n",
      "\n",
      " \n",
      "\n",
      "knowing know\n",
      "for for\n",
      "the the\n",
      "world world\n",
      "of of\n",
      "colour colour\n",
      "\n",
      " \n",
      "\n",
      "where where\n",
      "its -PRON-\n",
      "broad broad\n",
      "foundations foundation\n",
      "lie lie\n",
      ". .\n",
      "\n",
      " \n",
      "\n",
      "so so\n",
      "we -PRON-\n",
      "love love\n",
      "to to\n",
      "contemplate contemplate\n",
      "blue blue\n",
      "   \n",
      "— --\n",
      "   \n",
      "not not\n",
      "because because\n",
      "it -PRON-\n",
      "advances advance\n",
      "to to\n",
      "us -PRON-\n",
      ", ,\n",
      "but but\n",
      "because because\n",
      "it -PRON-\n",
      "draws draw\n",
      "us -PRON-\n",
      "after after\n",
      "it -PRON-\n",
      "\n",
      " \n",
      "\n",
      "but but\n",
      "how how\n",
      "i i\n",
      "was be\n",
      "astonished astonish\n",
      ", ,\n",
      "as as\n",
      "i i\n",
      "looked look\n",
      "at at\n",
      "a a\n",
      "white white\n",
      "wall wall\n",
      "through through\n",
      "the the\n",
      "prism prism\n",
      ", ,\n",
      "that that\n",
      "it -PRON-\n",
      "stayed stay\n",
      "white white\n",
      "! !\n",
      "that that\n",
      "only only\n",
      "where where\n",
      "it -PRON-\n",
      "came come\n",
      "upon upon\n",
      "some some\n",
      "darkened darken\n",
      "area area\n",
      ", ,\n",
      "it -PRON-\n",
      "showed show\n",
      "some some\n",
      "color color\n",
      ", ,\n",
      "then then\n",
      "at at\n",
      "last last\n",
      ", ,\n",
      "around around\n",
      "the the\n",
      "window window\n",
      "sill sill\n",
      "all all\n",
      "the the\n",
      "colors color\n",
      "shone shine\n",
      "… …\n",
      "it -PRON-\n",
      "did do\n",
      "n’t not\n",
      "take take\n",
      "long long\n",
      "before before\n",
      "i i\n",
      "knew know\n",
      "here here\n",
      "was be\n",
      "something something\n",
      "significant significant\n",
      "about about\n",
      "color color\n",
      "to to\n",
      "be be\n",
      "brought bring\n",
      "forth forth\n",
      ", ,\n",
      "and and\n",
      "i i\n",
      "spoke speak\n",
      "as as\n",
      "through through\n",
      "an an\n",
      "instinct instinct\n",
      "out out\n",
      "loud loud\n",
      ", ,\n",
      "that that\n",
      "the the\n",
      "newtonian newtonian\n",
      "teachings teaching\n",
      "were be\n",
      "false false\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for item in doc:\n",
    "    print(item.text, item.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lists per each pos_ type\n",
    "adjs    = [word.text for word in doc if word.pos_ == \"ADJ\"]\n",
    "adpos   = [word.text for word in doc if word.pos_ == \"ADP\"]\n",
    "advs    = [word.text for word in doc if word.pos_ == \"ADV\"]\n",
    "aux     = [word.text for word in doc if word.pos_ == \"AUX\"]\n",
    "conj    = [word.text for word in doc if word.pos_ == \"CONJ\"]\n",
    "co_conj = [word.text for word in doc if word.pos_ == \"CCONJ\"]\n",
    "deter   = [word.text for word in doc if word.pos_ == \"DET\"]\n",
    "inter   = [word.text for word in doc if word.pos_ == \"INTJ\"]\n",
    "noun    = [word.text for word in doc if word.pos_ == \"NOUN\"]\n",
    "num     = [word.text for word in doc if word.pos_ == \"NUM\"]\n",
    "part    = [word.text for word in doc if word.pos_ == \"PART\"]\n",
    "pron    = [word.text for word in doc if word.pos_ == \"PRON\"]\n",
    "proper  = [word.text for word in doc if word.pos_ == \"PROPN\"]\n",
    "sub_conj= [word.text for word in doc if word.pos_ == \"SCONJ\"]\n",
    "space   = [word.text for word in doc if word.pos_ == \"SPACE\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign each codon to a pos_ type\n",
    "lng_codon = {\"UUU\" : \"ADJ\", \"CUU\" : \"VERB\", \"AUU\" : \"ADV\", \"GUU\" : \"NOUN\",\n",
    "           \"UUC\" : \"ADJ\", \"CUC\" : \"VERB\", \"AUC\" : \"ADV\", \"GUC\" : \"NOUN\",\n",
    "           \"UUA\" : \"VERB\", \"CUA\" : \"VERB\", \"AUA\" : \"ADV\", \"GUA\" : \"NOUN\",\n",
    "           \"UUG\" : \"VERB\", \"CUG\" : \"VERB\", \"AUG\" : \"M\", \"GUG\" : \"NOUN\",\n",
    "           \"UCU\" : \"ADP\", \"CCU\" : \"AUX\", \"ACU\" : \"CONJ\", \"GCU\" : \"CCONJ\",\n",
    "           \"UCC\" : \"ADP\", \"CCC\" : \"AUX\", \"ACC\" : \"CONJ\", \"GCC\" : \"CCONJ\",\n",
    "           \"UCA\" : \"ADP\", \"CCA\" : \"AUX\", \"ACA\" : \"CONJ\", \"GCA\" :\"CCONJ\",\n",
    "           \"UCG\" : \"ADP\", \"CCG\" : \"AUX\", \"ACG\" : \"CONJ\", \"GCG\" : \"CCONJ\",\n",
    "           \"UAU\" : \"DET\", \"CAU\" : \"INTJ\", \"AAU\" : \"PART\", \"GAU\" : \"ADJ\",\n",
    "           \"UAC\" : \"DET\", \"CAC\" : \"INTJ\", \"AAC\" : \"PART\", \"GAC\" : \"ADJ\",\n",
    "           \"UAA\" : \"SPACE\", \"CAA\" : \"ADJ\", \"AAA\" : \"ADJ\", \"GAA\" : \"ADJ\",\n",
    "           \"UAG\" : \"SPACE\", \"CAG\" : \"ADJ\", \"AAG\" : \"ADJ\", \"GAG\" : \"PROPN\",\n",
    "           \"UGU\" : \"SCONJ\", \"CGU\" : \"LINE\", \"AGU\" : \"VERB\", \"GGU\" : \"PROPN\",\n",
    "           \"UGC\" : \"SCONJ\", \"CGC\" : \"PRON\", \"AGC\" : \"VERB\", \"GGC\" :\"PROPN\",\n",
    "           \"UGA\" : \"PRON\", \"CGA\" : \"PRON\", \"AGA\" : \"VERB\", \"GGA\" : \"PROPN\",\n",
    "           \"UGG\" : \"W\", \"CGG\" : \"PRON\", \"AGG\" : \"VERB\", \"GGG\" : \"PROPN\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dict with list of words per pos_ type\n",
    "list_pos = [\"ADJ\",\"ADP\",\"ADV\",\"AUX\",\"CONJ\",\"CCONJ\",\"DET\",\"INTJ\",\"NOUN\",\"NUM\",\"PART\",\"PRON\",\"PROPN\",\"PUNCT\",\"SCONJ\",\"SYM\",\"VERB\",\"X\",\"SPACE\"]\n",
    "pos_words = {}\n",
    "for pos in list_pos:\n",
    "    pos_words[pos] = [word.text for word in doc if word.pos_ == pos]\n",
    "    pos_words[\"LINE\"] = [\"\\n\\n\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINE\n"
     ]
    }
   ],
   "source": [
    "print( lng_codon[\"CGU\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advances not \n",
      " heaven cold has be white as \n",
      " \n",
      " different as of and intolerable appropriated blue \n",
      " false and pleasing \n",
      " safely say blue light blue unquiet is passive an it into blue were active retire to intense attenuated rather attractive to heaven blue it exciting gives other to but \n",
      " us blue to effect heaven very and appear colour be or and because its blue and \n",
      " lift yellow higher used cold upon effect account \n",
      "\n",
      " heaven higher on was its \n",
      " restless brings is at accompanied known exciting very as attenuated spoke but it a have larger to highest its lilac its blue very a us is melancholy increases a even ’s that in then when to to upper \n",
      " but black brought mildly empty \n"
     ]
    }
   ],
   "source": [
    "text_pos = \"\"\n",
    "for codon in group:\n",
    "    if codon in lng_codon.keys():\n",
    "        if (lng_codon[codon] == 'M' or lng_codon[codon] == 'W'):\n",
    "            continue\n",
    "        possible_words = pos_words[lng_codon[codon]]\n",
    "        if len(possible_words) > 0:\n",
    "            text_pos += random.sample(possible_words,1)[0] + ' '\n",
    "\n",
    "print(text_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heaven pure displays have active around \n",
    "   red of as but blue say sun \n",
    " melancholy and restless "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(text_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01110011011000010110011001100101011011000111100100100000011100110110000101111001001000000110001001101100011101010110010100100000011011000110100101100111011010000111010000100000011000100110110001110101011001010010000001110101011011100111000101110101011010010110010101110100001000000110100101110011001000000111000001100001011100110111001101101001011101100110010100100000011000010110111000100000011010010111010000100000011010010110111001110100011011110010000001100010011011000111010101100101001000000111011101100101011100100110010100100000011000010110001101110100011010010111011001100101001000000111001001100101011101000110100101110010011001010010000001110100011011110010000001101001011011100111010001100101011011100111001101100101001000000110000101110100011101000110010101101110011101010110000101110100011001010110010000100000011100100110000101110100011010000110010101110010001000000110000101110100011101000111001001100001011000110111010001101001011101100110010100100000011101000110111100100000011010000110010101100001011101100110010101101110001000000110001001101100011101010110010100100000011010010111010000100000011001010111100001100011011010010111010001101001011011100110011100100000011001110110100101110110011001010111001100100000011011110111010001101000011001010111001000100000011101000110111100100000011000100111010101110100001000000111010101110011001000000110001001101100011101010110010100100000011101000110111100100000011001010110011001100110011001010110001101110100001000000110100001100101011000010111011001100101011011100010000001110110011001010111001001111001001000000110000101101110011001000010000001100001011100000111000001100101011000010111001000100000011000110110111101101100011011110111010101110010001000000110001001100101001000000110111101110010001000000110000101101110011001000010000001100010011001010110001101100001011101010111001101100101001000000110100101110100011100110010000001100010011011000111010101100101001000000110000101101110011001000010000001101100011010010110011001110100001000000111100101100101011011000110110001101111011101110010000001101000011010010110011101101000011001010111001000100000011101010111001101100101011001000010000001100011011011110110110001100100001000000111010101110000011011110110111000100000011001010110011001100110011001010110001101110100001000000110000101100011011000110110111101110101011011100111010000100000\n"
     ]
    }
   ],
   "source": [
    "#text to dna\n",
    "a = 'safely say blue light blue unquiet is passive an it into blue were active retire to intense attenuated rather attractive to heaven blue it exciting gives other to but us blue to effect heaven very and appear colour be or and because its blue and lift yellow higher used cold upon effect account '\n",
    "a_bytes = bytes(a, \"ascii\")\n",
    "# print(a_bytes)\n",
    "a_string_bytes = [\"{0:b}\".format(x) for x in a_bytes]\n",
    "for i in range(len(a_string_bytes)):\n",
    "    while (len(a_string_bytes[i]) < 8):\n",
    "        a_string_bytes[i] = '0' + a_string_bytes[i]\n",
    "        \n",
    "a_string = ''.join(a_string_bytes)\n",
    "print(a_string)\n",
    "# print(' 0'.join([\"{0:b}\".format(x) for x in a_bytes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGTGCCGTAGTCAAAGCTGACGTCCGGAAGATCGTAGTAAATGTTAAGAATACCCAAGGGAATTATGCAAAGCTGGTAAGACTACCAACTTAAATCAGTCTTACCGTGATCTCTGCAGCGAAGACACACTGAGGCCATGCTAAGAGTCCGGTCTTATCAAAGGGCTCACAGACAAACGTCCCTCAGGCTTACCGTTATATATGACTAGACGACCACCTTTATCTAGGAGTGAAGGGCAAGATGGCTATATGCGAATCTTCAGCGCTTTCGCCACTAACAACGTATCATAGGGCAGGCATCCCACCGGTCCCCATGCCACGATTTCAGTAGGGAATTCTGCTCATCTTGCGTCATGACGCTAATCCCCCAGGCCCAGATTCGGGCACGACCCAAGTCTACTCTTGCTACACTCAAAAAGGCTCCTAGGCGTGACGTTCTCAATTCGGGGAATACAACAGTAACGCCGTAGTCCAGGTAGCGCTGCATATACTACCACATGTCTTTCTGCAGAGCTTGACTCAGTAAGATCCGACAACATGCAACTCGGCACGTATTTCGCACTTCTACTCGGTCGGAAGGAATCTAAGCCCAAATTTACTAAGGACTCTCGGGCGACAGGATCCTATGTCAGACGGCCTCGCAGACACAATTTATAACTGAGTGGCAGAACCAAGGAGACTCGTATGGAATGGCTAACTGCATCGATTCGGTAATGGACGTCGGCCGATCCGCACCAAGGAAACTATGTATCCCGGGCTACCGGCATATAGGCGTGAATTGCGCTCGTCCACTAGTTCGCAATTCCGCGAGGAATACACGAACAAAGTTCCGCCTGCACAGCTGTCGAAATGAGACCATGACGATCTGTACGCCCTAACCCCTGACACTAGGGATACATTTCGAACGTTCCGAATTCACAGAGTCCCGTAGGTCGACAGGCGCCTATTTAGTCCGTACTCTCCTAACCCAGGTAGAAATGAGTTTCATCAACCCGGCTAAAATTACTATCGGCAAAGCTTGCGTAAGGAATATATTATTTAACTCCCCAAGTCCATCAGTATGACATTGAGATCTGAATATAAGCCAACATGCTAAGCTGTATACACGAACACCGGAATCTATTTGCAACTTCAATTCTGAGCATCGGGCGCAATTCTAAGATGATTTCAGGCATTGAAGACCCCATGCAGTGATGAGCATCTTTCTTCATTACGATCGGGCCTGCCTCCCACAGTCGGTGCTGTCTACATGATCACCGGAAGAGATTTCATCCCTCCAACCTGGCGACCTTATTTTCCGCACAACGTCCAGACTTTAGATAGGTCGACCCGAACCAATGGCTCTAGTGCCTTAATAACAACTTCCATACTTAGTAACGGGCTAGATGCCGCGCCGACAAAAGTTCGAACGGCTGGTAATCACAAAGGCAGCTATGAAGTCATGAAGTCAGTACGAGCGGAACTTATGGCGACCCTAACCCAGTATACCATTACGATAGGAAAATCTGGAGGCCGTAATCTAGTAGGGAACTAACAAATTGAGTCCGTACGAGCGTGCAGAATGTTAATCAGCAACACGGACCCTATGCTTGCATGACTCAAAGCCACAATGCCACGCTTGAAACATTTACCAAGGCCGAGAGGACCCTCTTTACTCCCTCACAAATTACCTTCTGAGTGTCGGATTACCTTATGTTCGTTCTCTATTTACGAAAGCCAAAATTCACGCAGGCATATCATACAACAGTAGTGTAGTTCCGCACGCACCACTTCAACTCTTCGGGCATGAATAAACGAACACATGAAATACTTCAGCTCTGACATTCTGCCCCGCTGGATATAGGGCCTGCGGACTATAATCACACAGGCGAATCGGTATCCATTTAATTCATAAACCCTTCACGCCTGCTGACAGTTCTATATGACTATAAGCACAACGTAACAGATGATTTCCTGCATCCACGCCCCACGGAGGCCAGGATCATATTACGTACTTTCTCAAATACACCAGTTGACGATTCCGCTCGTAGTCCCGGCTTCAAGGAGGGTATGTCGGTCAGACCAACTTAGCAACTTAGCCTAGTAATGTAGGATAAACTTCATCTATGTACGACATACAACCGGTCGAGAGTGAAGGCTGCCGAGATGCCTAACATCCCCCCGTAAATGATGCTTGGCGTCGTCACTTAATACCAGCCCACATTGAGCTCGTGCCACAGGCGGGGCTGCGTGCCAGCAACCAGTAAGCTAGGCAGTAAGGAAGGACTTACTCGCGTACCGGCTGTATCCCCTCACACATGACCCGCGGCCATTCTTCAATTATTCTTGTCGTTCGAGAGGAGTGCAGGGATAACAGAAACA\n"
     ]
    }
   ],
   "source": [
    "#translator original#\n",
    "\n",
    "inputStr_ = a_string# TEXT\n",
    "\n",
    "outputStr = \"\"\n",
    "\n",
    "for num in inputStr:\n",
    "    if num == '0':\n",
    "        outputStr += random.sample(['A', 'C'], 1)[0]\n",
    "    elif num == '1':\n",
    "        outputStr += random.sample(['T', 'G'], 1)[0]\n",
    "\n",
    "print(outputStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safely say blue light blue unquiet is passive an it into blue were active retire to intense attenuated rather attractive to heaven blue it exciting gives other to but us blue to effect heaven very and appear colour be or and because its blue and lift yellow higher used cold upon effect account \n"
     ]
    }
   ],
   "source": [
    "# from: STACKOVERFLOW Vrom Python; DNA Sequence to AscII Text #\n",
    "\n",
    "\n",
    "tbl = str.maketrans('ACGT', '0011', '\\n \\ufeff')\n",
    "\n",
    "def dna_to_bytes(dna, offset=0):\n",
    "    \n",
    "    # Convert DNA letters to zero and one characters\n",
    "    bits = dna.translate(tbl)\n",
    "    # Convert groups of 8 zeros and ones to bytes, starting from `offset`\n",
    "    return bytes(int(bits[i:i+8], 2) for i in range(offset, len(bits), 8))\n",
    "\n",
    "dna = '''AGTGAATGCTTACACTAGGACTGAATGCCTATCGTCTGAACTGGGACGAAGAACCCCGTGCCGGCTGAAAAGATGGTAAGAATCACCCATTCCCTCCGTAGTCAAGTTCTCTCGTAATCGCCTCCCACAGTAGGACAGTCGACTATGACTTGAGTCGACACTGTAGACACGCCACCATGCAATAAGGCTGACCTTGCGATATGCAGCTCCTACACACGTTATAGAGGATGGACGTGACCTCTGTAGATCTGCTACTAGTCCTATATTTCGAACCGCCAACCGGAGCATAGGTACTGCCTCCCCAAGGGACACCGGCCCAGAGGGAATTCTGGCAGGCTGAGCAGCTGGCGTAATTCCGAGCAGACCAACGTCCAATCTTATTGCCCGAACCCATGAGCCGCTGGCTACAAGCCACAATTATCCGCGGCGTTCCGGGAGACCTTCGTGTCAGCACCCCGGAAAGCAGGCGTAACTGTATATATGACGAGAAGCACACAGTGATTGCGTCCTCGCGTGACGAAGGAATCTAATACCCCAGGCACAGAGTAAAGGATGTCTCCCTGCGCATCGTTATTCAGTCCGATCATACCAACGTTAATACTTCATCGATGGATACCGTCGAAGCGGGAAGACGTCCGATACGCCCAAATTGCTCAAGGATTGTCCTAAACCATTAGAATAGGCTGTAAGTGATACAGGCCTAGAGGAGTGCCTGGCCGGATGAAGATAAGAAAAAATTCAACTAGTTAGACATTGATACATGCAGATCGTCGTGCCGGTAGCGATTCAACTCTTTCTCACGGACGAGATTAATCAAAGACCAACTGGAAGACTTCCACGATGTCTACCTTATACAATGCAGATCTTTCATAAAGCCAAAAGTAACATCGGGATAAAGGTATAAAGTTCAGACTTCCACTCGGCACGTCTTGCTACCGTATCATCGTTATTACTGCATATCCGCACCAAGTGCGCCATGCGGTGAATCCCCCAGTATACCATTCCGCGATGCAACTCGGGAGTAATTACGCTCGTATGGCCAGACAAACGGCCCGCATTCTGCCCTTGAGCTCTGCAGAGAATCCCCAAGGCGCAGCTGGATACCCGCCACCATTCCTCGATGGGCAACGGAAATGCTGCTAATCGGGATCAAGTAGCCGCGGATGGCCTGCATTTAAGCCCCAAGTAATGTATTCTCCGATGTATTACTGCCTATCGGGAAGTCAGACCAAAGTCGTGGCGTGAGACCTTAGCCACTGAAGAGCGGTACTAACTCCAAAATGTATCCATGATGGGCCTCAAAAATGACCGAAGTTAGCTAGGGCTAAACTCCCACCGGGAGATAGGGCAGTCCGACACACTGAACTACTGCGGAACTGTCGCTAGGACTCTACTAACAAAGTGCGCAATGCGTTGACTACCCAATGACGCGATTAATGACTTCAGTAAGTAATCGCGTCCCGGATTTATCAACTACACCCTGCGAACCTGCCGCGAGTACCATCTTTCGGACTGCATATCGGAGGTACAGACCAAATTTATTCATTCAGCTCGTTACGACTTTGAATCAGCCACAAGGCACAGCGTAGGGACGTAAGCACCTACAACATGCCCCGATGGAAACCTTGCACAAGTCAGCTCTGCAAATAGGTCCGCACTCAACAATTAAATGCTTCGGTGCTTCTTAAAGGCTTTTATGGATCTCTTGCAGAAAGACCACATGCAAGCAGGCCTATCCGACACAATGAGGTTAGTGCCTACATCAAAACGGCCCAGCTGATGGCCTTCAGACCAGCCAAAATGCAATCATGCAGATCTGACCGGAGGCAACTCTGTCGCGCTGTACTTATTCATAGAAGCCAAAATGATACTCGTTATCAATTTAAGGCCGCCCAAATTAACGCCGTCGTACAGTTATATATTCATCTACTACCACCTTAAAAGATGCGGTCAGTACTCCCAGAACCCAGGCGTCCAGGCGCCTCTGCAGGACTTTCGAAACTAACAACTGTGAATAGTCCGATAGTCGGAAAGGCTGCCATTATTGTCTTGCGGGCCTAAACAATGCTAAAATGAGCATCGGCCGGGCGGAGAAACTTCCTAGCGGGCCTCCAGCCCAAAGGGAGATAGGTCAGGATGCATCTATTCCGACAAGCAACCCTTACAGTATTATTTGATTCGGACAGTAATACAATACCACAGGTAGCTAGGGAAACATTAGTGTCTTATGTCCATCAACCCGGACGCTAGGCAGTAATGCAGTCATTCCGAGCGTCACTTCTGGCTAACATCACCAAGGAAACTATGCCAGTAGGCAAGTCGGCTGGTCGGTCGCTATTCTGGCCTTTATCAAAGACCAC'''\n",
    "\n",
    "print(dna_to_bytes(dna).decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#short bp translationDNA #\n",
    "\n",
    "inputStr = a_string # ABCD\n",
    "outputStr = ''\n",
    "\n",
    "for start in range(0, len(inputStr), 2):\n",
    "    word = inputStr[start:start+2]\n",
    "    if word == '00': outputStr += 'A'\n",
    "    elif word == '01': outputStr += 'T'\n",
    "    elif word == '10': outputStr += 'C'\n",
    "    elif word == '11': outputStr += 'G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TGAGTCATTCTCTCTTTCGATGCTACAATGAGTCATTGCTACAATCACTCGATGTTTCTTACAATCGATCCTTCTGTCCATGTAACAATCACTCGATGTTTCTTACAATGTTTCGCTGATTGTTTCCTTCTTTGTAACAATCCTTGAGACAATGAATCATTGAGTGAGTCCTTGTCTCTTACAATCATTCGCACAATCCTTGTAACAATCCTTCGCTGTATCGGACAATCACTCGATGTTTCTTACAATGTGTCTTTGACTCTTACAATCATTCAGTGTATCCTTGTCTCTTACAATGACTCTTTGTATCCTTGACTCTTACAATGTATCGGACAATCCTTCGCTGTATCTTTCGCTGAGTCTTACAATCATTGTATGTATCTTTCGCTGTTTCATTGTATCTTTCTAACAATGACTCATTGTATCCATCTTTGACACAATCATTGTATGTATGACTCATTCAGTGTATCCTTGTCTCTTACAATGTATCGGACAATCCATCTTTCATTGTCTCTTTCGCACAATCACTCGATGTTTCTTACAATCCTTGTAACAATCTTTGCATCAGTCCTTGTATCCTTCGCTCTGACAATCTGTCCTTGTCTCTTTGAGACAATCGGTGTATCCATCTTTGACACAATGTATCGGACAATCACTGTTTGTAACAATGTTTGAGACAATCACTCGATGTTTCTTACAATGTATCGGACAATCTTTCTCTCTCTCTTTCAGTGTAACAATCCATCTTTCATTGTCTCTTTCGCACAATGTCTCTTTGACTGCTACAATCATTCGCTCTAACAATCATTGAATGAATCTTTCATTGACACAATCAGTCGGTCGATCGGTGTTTGACACAATCACTCTTACAATCGGTGACACAATCATTCGCTCTAACAATCACTCTTTCAGTCATTGTTTGAGTCTTACAATCCTTGTATGAGACAATCACTCGATGTTTCTTACAATCATTCGCTCTAACAATCGATCCTTCTCTGTAACAATGCTTCTTTCGATCGATCGGTGTGACAATCCATCCTTCTGTCCATCTTTGACACAATGTTTGAGTCTTTCTAACAATCAGTCGGTCGATCTAACAATGTTTGAATCGGTCGCACAATCTTTCTCTCTCTCTTTCAGTGTAACAATCATTCAGTCAGTCGGTGTTTCGCTGTAACAA'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590.0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputStr)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
